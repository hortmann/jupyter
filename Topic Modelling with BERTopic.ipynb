{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exposed-switch",
   "metadata": {},
   "source": [
    "### BERT Topic Modelling \n",
    "https://maartengr.github.io/BERTopic/index.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-chance",
   "metadata": {},
   "source": [
    "Some support functions to prepare text. BERTopic accepts list of str [str] as input. Cleaning is not mandatory. Normally use unckleaned text. But in the test case I used [sentences] and to get sentence tokens you need to clean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-domestic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "#################################################################################\n",
    "def clean_text(text,punctuation):\n",
    "    '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "    if punctuation:\n",
    "        text = re.sub('\\[.*?!\\]', ' ', text)#remove !\n",
    "        text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)#remove other punctuations\n",
    "    else:\n",
    "        text = text.lower() #to lower\n",
    "        #text = re.sub('\\w*\\d\\w*', '', text) #clearing digits\n",
    "        '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''\n",
    "        text = re.sub('[\\n*]', ' . ', text)\n",
    "        text = re.sub('[/‘’“”…]', '', text)\n",
    "        text = re.sub('\\u20AC', '', text)#remove € \n",
    "        text = re.sub('\\xa0', ' ', text)\n",
    "        text=multi_del_recurse(text,'\\.')\n",
    "    return text# indexing the words in sentences with running index numbers and returns a list of dicts or json\n",
    "\n",
    "#################################################################################\n",
    "'#recursisive deletion of multi characters ch1'\n",
    "def multi_del_recurse(t,ch1):\n",
    "    ch=ch1+ch1\n",
    "    if re.search(ch, t)!= None :\n",
    "        t1=re.sub(r'\\\\','','\\.')\n",
    "        t=re.sub(ch,t1,t)\n",
    "        return(multi_del_recurse(t,ch1))\n",
    "    else:\n",
    "        return t\n",
    "#################################################################################    \n",
    "def load_files():\n",
    "    \n",
    "    jd_txt=open('Z:\\\\SEMP_JD.txt').read()\n",
    "    jd_cl=clean_text(jd_txt,False)\n",
    "    jd_sent=sent_tokenize(jd_cl)\n",
    "    res_txt=open('Z:\\\\SEMP_RES1.txt').read()\n",
    "    res_cl=clean_text(res_txt,False)\n",
    "    res_sent=sent_tokenize(res_cl)\n",
    "\n",
    "    while '.' in jd_sent: jd_sent.remove('.')\n",
    "    while '.' in res_sent: res_sent.remove('.')\n",
    "    return(jd_cl,jd_sent,res_cl,res_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunset-schema",
   "metadata": {},
   "source": [
    "### Here it starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "abstract-world",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# Accepts a list of text strings ( document(s) and returns info about Topics and writes JSON File)\n",
    "\n",
    "def get_topics():\n",
    "    from bertopic import BERTopic\n",
    "    from sklearn.datasets import fetch_20newsgroups\n",
    "    import json\n",
    "\n",
    "    JPATH='Z:/FILES/OUTPUT/JSON/'\n",
    "    #docs = fetch_20newsgroups(subset='all',  remove=('headers', 'footers', 'quotes'))['data']\n",
    "\n",
    "    # I used our jd and resume from semperit and Jon\n",
    "    jd_cl,jd_sent,res_cl,res_sent=load_files()\n",
    "\n",
    "    #we use sentnteces in JD Document\n",
    "    docs=jd_sent\n",
    "\n",
    "    #instantiate a model\n",
    "    topic_model = BERTopic(embedding_model='sentence-transformers/paraphrase-MiniLM-L6-v2',min_topic_size=2,calculate_probabilities=True)\n",
    "\n",
    "    #fit your documents ( List[str]) to the model\n",
    "    # we will get different results each time we run - reason:use of stochatic models\n",
    "    topics, _ = topic_model.fit_transform(docs)\n",
    "    info_df=topic_model.get_topic_info()\n",
    "\n",
    "    t_scores=topic_model.get_topics()\n",
    "\n",
    "    # you even can use graphics\n",
    "    #topic_model.visualize_topics()\n",
    "\n",
    "    #write to jason file \n",
    "    result = info_df.to_json(orient=\"split\")\n",
    "    print(result)\n",
    "    with open(JPATH+'BERTopic.json', 'w') as f:\n",
    "        f.write(result)\n",
    "        f.close\n",
    "    return(topics,result,info_df,t_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "amino-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"columns\":[\"Topic\",\"Count\",\"Name\"],\"index\":[0,1,2,3],\"data\":[[0,14,\"0_location_vienna_work_experience\"],[1,9,\"1_management_service_strategy_maintain\"],[-1,5,\"-1_service_regulations_ensures_guaranteed\"],[2,3,\"2_desk_service_complaints_efficiency\"]]}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>0_location_vienna_work_experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1_management_service_strategy_maintain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1_service_regulations_ensures_guaranteed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2_desk_service_complaints_efficiency</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic  Count                                       Name\n",
       "0      0     14          0_location_vienna_work_experience\n",
       "1      1      9     1_management_service_strategy_maintain\n",
       "2     -1      5  -1_service_regulations_ensures_guaranteed\n",
       "3      2      3       2_desk_service_complaints_efficiency"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics,results,info_df,t_scores=get_topics()\n",
    "info_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
